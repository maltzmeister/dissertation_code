{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc49a3c-c05e-4ded-a532-c504d1cca89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "import gc\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "tf_folder = \"pdb_TF_files\"\n",
    "non_tf_folder = \"pdb_non_TF_files\"\n",
    "\n",
    "os.makedirs(tf_folder, exist_ok=True)\n",
    "os.makedirs(non_tf_folder, exist_ok=True)\n",
    "\n",
    "conn = sqlite3.connect(\"dissertation_SQLitev1.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "create_table_SQLite = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS protein_summary_table (\n",
    "    UniProt_id TEXT PRIMARY KEY,\n",
    "    Is_TF INTEGER NOT NULL,\n",
    "    Entry_Name TEXT NOT NULL,\n",
    "    DBD TEXT,\n",
    "    Length_UniProt INTEGER NOT NULL,\n",
    "    Length_AlphaFold INTEGER NOT NULL,\n",
    "    AlphaFold_Species TEXT NOT NULL,\n",
    "    AlphaFold_UniProt_id TEXT NOT NULL,\n",
    "    AlphaFold_Entry_Name TEXT NOT NULL,\n",
    "    AlphaFold_is_reference_proteome INTEGER NOT NULL,\n",
    "    average_pLDDT_for_entire_protein REAL NOT NULL,\n",
    "    num_disordered_res INTEGER NOT NULL,\n",
    "    num_ordered_res INTEGER NOT NULL,\n",
    "    percent_disordered_res_for_entire_protein REAL NOT NULL,\n",
    "    N_terminal_IDR_presence INTEGER NOT NULL,\n",
    "    N_IDR_length_over_10 INTEGER NOT NULL,\n",
    "    C_terminal_IDR_presence INTEGER NOT NULL,\n",
    "    C_IDR_length_over_10 INTEGER NOT NULL,\n",
    "    Disordered_tail_N_or_C_presence INTEGER NOT NULL,\n",
    "    Disordered_tails_N_and_C_presence INTEGER NOT NULL,\n",
    "    n_IDR_pLDDT_mean REAL,\n",
    "    c_IDR_pLDDT_mean REAL,\n",
    "    number_of_dis_regions_over_10_res INTEGER NOT NULL,\n",
    "    disordered_regions TEXT,\n",
    "    average_length_dis_region REAL NOT NULL,\n",
    "    longest_length_dis_region INTEGER NOT NULL,\n",
    "    shortest_length_dis_region INTEGER NOT NULL\n",
    "    \n",
    "    \n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_table_SQLite)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "\n",
    "\n",
    "def fetch_protein_pdb_file(uniprot_acc):\n",
    "    url = f\"https://alphafold.ebi.ac.uk/api/prediction/{uniprot_acc}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data[0][\"pdbUrl\"]\n",
    "\n",
    "    else:\n",
    "        print(f\"Error fetching {uniprot_acc}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_AlphaFold_data(uniprot_acc):\n",
    "    url = f\"https://alphafold.ebi.ac.uk/api/prediction/{uniprot_acc}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        AlphaFold_dict = {\n",
    "            \"AlphaFold_Species\": data[0][\"organismScientificName\"],\n",
    "            \"AlphaFold_UniProt_id\": data[0][\"uniprotAccession\"],\n",
    "            \"AlphaFold_Entry_Name\": data[0][\"uniprotId\"],\n",
    "            \"AlphaFold_is_reference_proteome\": int(data[0][\"isReferenceProteome\"]),\n",
    "            \"AlphaFold_pdbUrl\": data[0][\"pdbUrl\"]\n",
    "        }\n",
    "        return AlphaFold_dict\n",
    "\n",
    "    else:\n",
    "        print(f\"Error fetching {uniprot_acc}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def download_pdb_file(pdb_URL, pdb_file_name):\n",
    "    response = requests.get(pdb_URL)\n",
    "    if response.status_code == 200:\n",
    "        with open(pdb_file_name, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"file {pdb_file_name} successfully downloaded\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to download the file for {pdb_file_name}. Status code: {response.status_code}\")\n",
    "        return False\n",
    "\n",
    "        \n",
    "def parse_pdb_file(pdb_file_path):\n",
    "    structure = parser.get_structure(\"AlphaFold\", pdb_file_path)\n",
    "\n",
    "    data = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                if residue.has_id(\"CA\"):\n",
    "                    ca_atom = residue[\"CA\"]\n",
    "                    data.append({\n",
    "                        \"residue\": residue.get_resname(),\n",
    "                        \"chain\": chain.id,\n",
    "                        \"residue_id\": residue.id[1],\n",
    "                        \"pLDDT\": ca_atom.get_bfactor(),\n",
    "                    })\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_IDR_over_10_in_termini(pLDDT_df_n_and_c):\n",
    "    df_sorted = pLDDT_df_n_and_c.sort_values(\"residue_id\")\n",
    "    threshold_pLDDT_score = 68.8\n",
    "\n",
    "    n_terminal_df = df_sorted.head(10)\n",
    "    n_terminal_disordered = (n_terminal_df[\"pLDDT\"] < threshold_pLDDT_score).all()\n",
    "    n_terminal_disordered_integer = int(n_terminal_disordered)\n",
    "    n_IDR_length_over_10 = 0\n",
    "    n_IDR_pLDDT_mean = None\n",
    "    if n_terminal_disordered:\n",
    "        for _, row in df_sorted.iterrows():\n",
    "            if row[\"pLDDT\"] < threshold_pLDDT_score:\n",
    "                n_IDR_length_over_10 += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    if n_terminal_disordered:\n",
    "        n_IDR_df = df_sorted.iloc[:n_IDR_length_over_10]\n",
    "        n_IDR_pLDDT_mean = n_IDR_df[\"pLDDT\"].mean()\n",
    "            \n",
    "            \n",
    "\n",
    "    c_terminal_df = df_sorted.tail(10)\n",
    "    c_terminal_disordered = (c_terminal_df[\"pLDDT\"] < threshold_pLDDT_score).all()\n",
    "    c_terminal_disordered_integer = int(c_terminal_disordered)\n",
    "    c_IDR_length_over_10 = 0\n",
    "    c_IDR_pLDDT_mean = None\n",
    "    if c_terminal_disordered:\n",
    "        for _, row in df_sorted.iloc[::-1].iterrows():\n",
    "            if row[\"pLDDT\"] < threshold_pLDDT_score:\n",
    "                c_IDR_length_over_10 += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    if c_terminal_disordered:\n",
    "        c_IDR_df = df_sorted.iloc[:-c_IDR_length_over_10:-1]\n",
    "        c_IDR_pLDDT_mean = c_IDR_df[\"pLDDT\"].mean()\n",
    "\n",
    "    return {\n",
    "        \"N_terminal_IDR_presence\": n_terminal_disordered_integer,\n",
    "        \"N_IDR_length_over_10\": n_IDR_length_over_10,\n",
    "        \"C_terminal_IDR_presence\": c_terminal_disordered_integer,\n",
    "        \"C_IDR_length_over_10\": c_IDR_length_over_10,\n",
    "        \"Disordered_tail_N_or_C_presence\": int(n_terminal_disordered or c_terminal_disordered),\n",
    "        \"Disordered_tails_N_and_C_presence\": int(n_terminal_disordered and c_terminal_disordered),\n",
    "        \"n_IDR_pLDDT_mean\": n_IDR_pLDDT_mean if n_terminal_disordered else None,\n",
    "        \"c_IDR_pLDDT_mean\": c_IDR_pLDDT_mean if c_terminal_disordered else None\n",
    "    }\n",
    "\n",
    "\n",
    "def analyse_disorder_of_whole_protein(pLDDT_df, additional_dict=None):\n",
    "    termini_function_results = check_IDR_over_10_in_termini(pLDDT_df)\n",
    "\n",
    "    disordered_residues = pLDDT_df.loc[pLDDT_df.pLDDT < 68.8]\n",
    "    disordered_residues = disordered_residues.sort_values(\"residue_id\")\n",
    "\n",
    "    prev_res_id = disordered_residues.residue_id.min() - 1\n",
    "    consecutive_count = 0\n",
    "    region_count = 0\n",
    "    min_length = 10\n",
    "    segments = []\n",
    "\n",
    "    for index, row in disordered_residues.iterrows():\n",
    "        current_res_id = row[\"residue_id\"]\n",
    "        \n",
    "        if current_res_id == prev_res_id + 1:\n",
    "            consecutive_count += 1\n",
    "        else:\n",
    "            if consecutive_count >= min_length:\n",
    "                region_count += 1\n",
    "                segments.append(consecutive_count)\n",
    "            consecutive_count = 1\n",
    "            \n",
    "        \n",
    "        prev_res_id = current_res_id\n",
    "\n",
    "    if consecutive_count >= min_length:\n",
    "        region_count += 1\n",
    "        segments.append(consecutive_count)\n",
    "\n",
    "    average_pLDDT_for_entire_protein = pLDDT_df[\"pLDDT\"].mean()\n",
    "    num_disordered_res = len(disordered_residues)\n",
    "    percent_disordered_res_for_entire_protein = (num_disordered_res / len(pLDDT_df)) * 100\n",
    "    number_of_dis_regions_over_10_res = region_count\n",
    "    disordered_regions = segments\n",
    "    disordered_regions_serialized = json.dumps(disordered_regions)\n",
    "    average_length_dis_region = sum(segments) / len(segments) if len(segments) > 0 else 0\n",
    "    longest_length_dis_region = max(segments) if len(segments) > 0 else 0\n",
    "    shortest_length_dis_region = min(segments) if len(segments) > 0 else 0\n",
    "\n",
    "    if additional_dict is not None:\n",
    "        results_dict = {\n",
    "        \"UniProt_id\": additional_dict[\"UniProt_id\"],\n",
    "        \"Is_TF\": additional_dict[\"Is_TF\"],\n",
    "        \"Entry_Name\":additional_dict[\"Entry_Name\"],\n",
    "        \"DBD\": additional_dict[\"DBD\"],\n",
    "        \"Length_UniProt\": additional_dict[\"Length\"],\n",
    "        \"Length_AlphaFold\": len(pLDDT_df),\n",
    "        \"AlphaFold_Species\": additional_dict[\"AlphaFold_Species\"],\n",
    "        \"AlphaFold_UniProt_id\": additional_dict[\"AlphaFold_UniProt_id\"],\n",
    "        \"AlphaFold_Entry_Name\": additional_dict[\"AlphaFold_Entry_Name\"],\n",
    "        \"AlphaFold_is_reference_proteome\": additional_dict[\"AlphaFold_is_reference_proteome\"], \n",
    "        \"average_pLDDT_for_entire_protein\": average_pLDDT_for_entire_protein,\n",
    "        \"num_disordered_res\": num_disordered_res,\n",
    "        \"num_ordered_res\": len(pLDDT_df) - num_disordered_res,\n",
    "        \"percent_disordered_res_for_entire_protein\": percent_disordered_res_for_entire_protein,\n",
    "        \"N_terminal_IDR_presence\": termini_function_results[\"N_terminal_IDR_presence\"],\n",
    "        \"N_IDR_length_over_10\": termini_function_results[\"N_IDR_length_over_10\"],\n",
    "        \"C_terminal_IDR_presence\": termini_function_results[\"C_terminal_IDR_presence\"],\n",
    "        \"C_IDR_length_over_10\": termini_function_results[\"C_IDR_length_over_10\"],\n",
    "        \"Disordered_tail_N_or_C_presence\": termini_function_results[\"Disordered_tail_N_or_C_presence\"],\n",
    "        \"Disordered_tails_N_and_C_presence\": termini_function_results[\"Disordered_tails_N_and_C_presence\"],\n",
    "        \"n_IDR_pLDDT_mean\": termini_function_results[\"n_IDR_pLDDT_mean\"],\n",
    "        \"c_IDR_pLDDT_mean\": termini_function_results[\"c_IDR_pLDDT_mean\"],\n",
    "        \"number_of_dis_regions_over_10_res\": number_of_dis_regions_over_10_res,\n",
    "        \"disordered_regions\": disordered_regions_serialized,\n",
    "        \"average_length_dis_region\": average_length_dis_region,\n",
    "        \"longest_length_dis_region\": longest_length_dis_region,\n",
    "        \"shortest_length_dis_region\": shortest_length_dis_region\n",
    "        \n",
    "    }\n",
    "    else:\n",
    "        results_dict = {\n",
    "        \n",
    "        \"average_pLDDT_for_entire_protein\": average_pLDDT_for_entire_protein,\n",
    "        \"Length_AlphaFold\": len(pLDDT_df),\n",
    "        \"num_disordered_res\": num_disordered_res,\n",
    "        \"num_ordered_res\": len(pLDDT_df) - num_disordered_res,\n",
    "        \"percent_disordered_res_for_entire_protein\": percent_disordered_res_for_entire_protein,\n",
    "        \"N_terminal_IDR_presence\": termini_function_results[\"N_terminal_IDR_presence\"],\n",
    "        \"N_IDR_length_over_10\": termini_function_results[\"N_IDR_length_over_10\"],\n",
    "        \"C_terminal_IDR_presence\": termini_function_results[\"C_terminal_IDR_presence\"],\n",
    "        \"C_IDR_length_over_10\": termini_function_results[\"C_IDR_length_over_10\"],\n",
    "        \"Disordered_tail_N_or_C_presence\": termini_function_results[\"Disordered_tail_N_or_C_presence\"],\n",
    "        \"Disordered_tails_N_and_C_presence\": termini_function_results[\"Disordered_tails_N_and_C_presence\"],\n",
    "        \"n_IDR_pLDDT_mean\": termini_function_results[\"n_IDR_pLDDT_mean\"],\n",
    "        \"c_IDR_pLDDT_mean\": termini_function_results[\"c_IDR_pLDDT_mean\"],\n",
    "        \"number_of_dis_regions_over_10_res\": number_of_dis_regions_over_10_res,\n",
    "        \"disordered_regions\": disordered_regions,\n",
    "        \"average_length_dis_region\": average_length_dis_region,\n",
    "        \"longest_length_dis_region\": longest_length_dis_region,\n",
    "        \"shortest_length_dis_region\": shortest_length_dis_region\n",
    "        \n",
    "    }\n",
    "        \n",
    "    \n",
    "\n",
    "    df = pd.DataFrame([results_dict])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def extract_UniProt_DBD_isTF_Entry_Name_and_Length(input_df_row):\n",
    "    information = {\n",
    "        \"UniProt_id\": input_df_row[\"UniProt_id\"],\n",
    "        \"DBD\": input_df_row[\"DBD\"],\n",
    "        \"Is_TF\": input_df_row[\"Is_TF\"],\n",
    "        \"Entry_Name\":input_df_row[\"Entry_Name\"],\n",
    "        \"Length\": input_df_row[\"Length\"]\n",
    "    }\n",
    "    return information\n",
    "\n",
    "def insert_protein_summary_results_into_SQLite(input_df, conn, table_name=\"protein_summary_table\"):\n",
    "    try:\n",
    "        UniProt = input_df[\"UniProt_id\"].iat[0]\n",
    "        input_df.to_sql(table_name, conn, if_exists=\"append\", index = False)\n",
    "        conn.commit()\n",
    "        print(f\"data for {UniProt} added to {table_name}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"\"\"\n",
    "\n",
    "        \n",
    "        unable to add {UniProt} to {table_name}: {e}\n",
    "\n",
    "        \n",
    "        \"\"\")\n",
    "        return e\n",
    "\n",
    "def combine_metadata_dictionaries(UniProt_dict, AlphaFold_dict):\n",
    "    combined_dict = {\n",
    "        \"UniProt_id\": UniProt_dict[\"UniProt_id\"],\n",
    "        \"DBD\": UniProt_dict[\"DBD\"],\n",
    "        \"Is_TF\": UniProt_dict[\"Is_TF\"],\n",
    "        \"Entry_Name\":UniProt_dict[\"Entry_Name\"],\n",
    "        \"Length\": UniProt_dict[\"Length\"],\n",
    "        \"AlphaFold_Species\": AlphaFold_dict[\"AlphaFold_Species\"],\n",
    "        \"AlphaFold_UniProt_id\": AlphaFold_dict[\"AlphaFold_UniProt_id\"],\n",
    "        \"AlphaFold_Entry_Name\": AlphaFold_dict[\"AlphaFold_Entry_Name\"],\n",
    "        \"AlphaFold_is_reference_proteome\": AlphaFold_dict[\"AlphaFold_is_reference_proteome\"],\n",
    "    }\n",
    "    return combined_dict\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def master_function(input_data_type):\n",
    "    try:\n",
    "        if isinstance(input_data_type, list):\n",
    "            results = []\n",
    "            for accession in input_data_type:\n",
    "                file_name = f\"{accession}.pdb\"\n",
    "                pdb_url = fetch_protein_pdb_file(accession)\n",
    "                download_pdb_file(pdb_url, file_name)\n",
    "                dataframes = parse_pdb_file(file_name)\n",
    "                whole_protein_analysis = analyse_disorder_of_whole_protein(dataframes)\n",
    "                results.append(whole_protein_analysis)\n",
    "            return results\n",
    "\n",
    "        elif isinstance(input_data_type, str):\n",
    "            file_name = f\"{input_data_type}.pdb\"\n",
    "            pdb_url = fetch_protein_pdb_file(input_data_type)\n",
    "            download_pdb_file(pdb_url, file_name)\n",
    "            dataframes = parse_pdb_file(file_name)\n",
    "            analysis_summary = analyse_disorder_of_whole_protein(dataframes)\n",
    "            return analysis_summary\n",
    "            \n",
    "        elif isinstance(input_data_type, pd.DataFrame):\n",
    "            unfound_protein_accessions = []\n",
    "            for _, row in input_data_type.iterrows():\n",
    "                row_information = extract_UniProt_DBD_isTF_Entry_Name_and_Length(row)\n",
    "                accession = row[\"UniProt_id\"]\n",
    "                is_TF = row[\"Is_TF\"]\n",
    "                if (is_TF == 1):\n",
    "                    folder_name = \"pdb_TF_files\"\n",
    "                elif (is_TF == 0):\n",
    "                    folder_name = \"pdb_non_TF_files\"\n",
    "                file_name = os.path.join(folder_name, f\"{accession}.pdb\")\n",
    "                AlphaFold_pdb_and_metadata = fetch_AlphaFold_data(accession)\n",
    "\n",
    "                if AlphaFold_pdb_and_metadata is None:\n",
    "                    unfound_protein_accessions.append({\"accession\": accession, \"reason\": \"failed API call\"})\n",
    "                    print(f\"\"\"\n",
    "\n",
    "                    \n",
    "                    Skipping {accession} - not found in AlphaFold API call.\n",
    "                    \n",
    "                    \n",
    "                    \"\"\")\n",
    "                    continue\n",
    "\n",
    "                if (AlphaFold_pdb_and_metadata[\"AlphaFold_UniProt_id\"] != accession):\n",
    "                    unfound_protein_accessions.append({\"accession\": accession, \"reason\": \"wrong UniProt id\"})\n",
    "                    print(f\"\"\"\n",
    "\n",
    "                    \n",
    "                    Skipping {accession} - wrong UniProt id\n",
    "                    \n",
    "                    \n",
    "                    \"\"\")\n",
    "                    continue\n",
    "                    \n",
    "                \n",
    "                downloaded_status = download_pdb_file(AlphaFold_pdb_and_metadata[\"AlphaFold_pdbUrl\"], file_name)\n",
    "                if downloaded_status == False:\n",
    "                    unfound_protein_accessions.append({\"accession\": accession, \"reason\": \"failed download\"})\n",
    "                    print(f\"\"\"\n",
    "\n",
    "                    \n",
    "                    Skipping {accession} - download failed.\n",
    "                    \n",
    "                    \n",
    "                    \"\"\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    metadata_dict = combine_metadata_dictionaries(row_information, AlphaFold_pdb_and_metadata)\n",
    "                    dataframes = parse_pdb_file(file_name)\n",
    "                    whole_protein_analysis = analyse_disorder_of_whole_protein(dataframes, metadata_dict)\n",
    "                    SQLite_status = insert_protein_summary_results_into_SQLite(whole_protein_analysis, conn)\n",
    "                    if SQLite_status != True:\n",
    "                        unfound_protein_accessions.append({\"accession\": accession, \"reason\": SQLite_status})\n",
    "\n",
    "                finally:\n",
    "                    try:\n",
    "                        del dataframes\n",
    "                        del whole_protein_analysis\n",
    "                    except NameError:\n",
    "                        pass\n",
    "                    gc.collect()\n",
    "                        \n",
    "                \n",
    "            if (len(unfound_protein_accessions) > 0):\n",
    "                bad_accessions = \"\\n\".join(f\"{i+1}: {f['accession']}, {f['reason']}\" for i, f in enumerate(unfound_protein_accessions))\n",
    "                print(f\"\"\"\n",
    "                {len(unfound_protein_accessions)} protein/s failed to be added to SQLite\n",
    "                {bad_accessions}\n",
    "                \"\"\")\n",
    "            else:\n",
    "                print(\"ALL proteins added successfully\")\n",
    "                \n",
    "            return None\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            raise TypeError(\"Input not a string, list, or dataframe\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_data_type}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
